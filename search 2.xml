<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hadoop技术内幕-Hadoop 配置信息处理</title>
    <url>/2016/04/01/Hadoop%20%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h1 id="Hadoop-配置信息处理"><a href="#Hadoop-配置信息处理" class="headerlink" title="Hadoop 配置信息处理"></a>Hadoop 配置信息处理</h1><h2 id="配置信息处理方式简介"><a href="#配置信息处理方式简介" class="headerlink" title="配置信息处理方式简介"></a>配置信息处理方式简介</h2><h3 id="Java配置文件"><a href="#Java配置文件" class="headerlink" title="Java配置文件"></a>Java配置文件</h3><p>Java一般操作配置文件的方式是通过<code>java.util.Properties</code>类来处理的，其中<code>java.util.Properties</code>中包含了一些常用的配置文件属性的处理，不过仅仅是支持简单的键值对操作</p>
<blockquote>
<p>mac:没有tree命令，Windows和Linux均有tree命令，使用find命令进行模拟<code>find . -print | sed -e &#39;s;[^/]*/;|_;g;s;_|; |;g&#39;</code></p>
</blockquote>
<h4 id="文件目录结构"><a href="#文件目录结构" class="headerlink" title="文件目录结构"></a>文件目录结构</h4><p>当前项目文件结构为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">|_src</span><br><span class="line">| |_test</span><br><span class="line">| | |_java</span><br><span class="line">| |_main</span><br><span class="line">| | |_resources</span><br><span class="line">| | | |_TestConfig.prop</span><br><span class="line">| | |_java</span><br><span class="line">| | | |_com</span><br><span class="line">| | | | |_zixiu</span><br><span class="line">| | | | | |_khaos</span><br><span class="line">| | | | | | |_TestConfig.java</span><br></pre></td></tr></table></figure>

<h4 id="配置文件信息"><a href="#配置文件信息" class="headerlink" title="配置文件信息"></a>配置文件信息</h4><p>其中<code>TestConfig.java</code>内容如下：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">hadoop.dir</span>=<span class="string">/home/hadoop</span></span><br><span class="line"><span class="meta">hadoop.log</span>=<span class="string">/var/log/hadoop</span></span><br></pre></td></tr></table></figure>

<h4 id="Java读取配置文件方式"><a href="#Java读取配置文件方式" class="headerlink" title="Java读取配置文件方式"></a>Java读取配置文件方式</h4><p>Java通过Properties类进行配置文件操作如下：</p>
<blockquote>
<p>本文使用相对路径读取配置文件信息方式</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestConfig</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        InputStream propertiesStream = TestConfig.class.getClassLoader().getResourceAsStream("TestConfig.prop");</span><br><span class="line">        properties.load(propertiesStream);</span><br><span class="line">        String hadoopDirPath = properties.getProperty(<span class="string">"hadoop.dir"</span>);</span><br><span class="line">        System.out.println(hadoopDirPath);</span><br><span class="line">        String hadoopLogPath = properties.getProperty(<span class="string">"hadoop.log"</span>);</span><br><span class="line">        System.out.println(hadoopLogPath);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//读取配置文件信息</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">load</span><span class="params">(InputStream inStream)</span> <span class="keyword">throws</span> IOException</span>&#123;...&#125;</span><br><span class="line"><span class="comment">//获取配置信息</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getProperty</span><span class="params">(String key)</span> </span>&#123;...&#125;</span><br><span class="line"><span class="comment">//设置配置信息</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> Object <span class="title">setProperty</span><span class="params">(String key, String value)</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Hadoop配置文件操作"><a href="#Hadoop配置文件操作" class="headerlink" title="Hadoop配置文件操作"></a>Hadoop配置文件操作</h3><h4 id="Hadoop配置文件格式"><a href="#Hadoop配置文件格式" class="headerlink" title="Hadoop配置文件格式"></a>Hadoop配置文件格式</h4><p>Hadoop配置文件采用XML方式存储配置信息，主要格式如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>build/test<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>A base for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">final</span>&gt;</span>true<span class="tag">&lt;/<span class="name">final</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.ftp.user.localhost<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>user<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The username for connecting to FTP server running on localhost.</span><br><span class="line">            This is required by FTPFileSystem</span><br><span class="line">        <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.ftp.password.localhost<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>password<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The password for connecting to FTP server running on localhost.</span><br><span class="line">            This is required by FTPFileSystem</span><br><span class="line">        <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- Turn security off for tests by default --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.security.authentication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>simple<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>nfs3.server.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2079<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>nfs3.mountd.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4272<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>一般情况下，根结点为<code>configuration</code>,子节点为<code>property</code>，主要包含<code>name</code>和<code>value</code>节点存储配置信息，<code>description</code>节点存储配置信息描述,<code>final</code>节点表示为该节点属性为最终属性不可覆盖，防止该属性被修改覆盖。</p>
<h4 id="Configuration类"><a href="#Configuration类" class="headerlink" title="Configuration类"></a>Configuration类</h4><p>Hadoop的配置是通过<code>Configuration</code>类进行处理的，是Hadoop实现的配置处理类。</p>
<h5 id="类结构"><a href="#类结构" class="headerlink" title="类结构"></a>类结构</h5><p>如下是<code>Configuration</code>的类图<br><img src="https://i.imgur.com/gFVocBz.png" alt="Configuration"></p>
<h5 id="常用方法介绍"><a href="#常用方法介绍" class="headerlink" title="常用方法介绍"></a>常用方法介绍</h5><ul>
<li>quietMode: 代表加载模式，调试时候使用</li>
<li>resources: 是当前需要加载的配置资源对象，可能是文件，或者流信息</li>
<li>finalParameters: 记录配置文件设置为final的属性</li>
<li>loadDefault: 是否要加载默认资源</li>
<li>defaultResources: 默认资源的数组对象</li>
<li>Properties: 普通的属性对象</li>
<li>overlay: 记录通过set方法改变的属性信息</li>
<li>classLoader: 用来处理配置文件资源加载</li>
<li>addResource: 添加资源方法</li>
<li>reloadConfiguration: 重新加载配置文件会清空之前的配置信息</li>
<li>loadResources*(): </li>
</ul>
<blockquote>
<p>Hadoop属性的获取是懒加载的方式，在getProps时，先去判断是否为空，如果为空再去加载配置文件中的属性。</p>
</blockquote>
<h5 id="解析方式"><a href="#解析方式" class="headerlink" title="解析方式"></a>解析方式</h5><p>因为Hadoop的配置文件比较零碎，并没有所有配置文件放在一个文件中，可以通过XML文档的XInclude属性，将其他的XML文档包含近当前文件中，如</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">xi:include</span> <span class="attr">href</span>=<span class="string">"other.xml"</span> <span class="attr">xmlns:xi</span>=<span class="string">"http://www.w3.org/2003/XInclude"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>通过该机制可以将所需的配置文件进行整合使用，并且相对Hadoop来说仅仅需要加载当前的Config文件而不用去加载其中引入的文件。</p>
<blockquote>
<p>常用解析XML文件的方式为SAX和DOM解析，因为Hadoop配置文件碎片化明显，选用DOM解析XML文件</p>
</blockquote>
<p>Hadoop的属性配置可以通过<code>substituteVars()</code>方法来对属性进行拓展，拓展方式时通过正则表达式对当前属性值进行匹配，重新替换。如果属性<code>${key1}</code>替换为<code>${key2}</code>,属性<code>${key2}</code>又替换为<code>${key1}</code>,则会导致死循环的产生，Hadoop通过设置静态成员变量<code>MAX_SUBST=20</code>设置最大的循环替换次数为20次。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark-History服务器角色日志报错</title>
    <url>/2020/05/29/Spark-History%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A7%92%E8%89%B2%E6%97%A5%E5%BF%97%E6%8A%A5%E9%94%99/</url>
    <content><![CDATA[<h1 id="Spark-History服务器角色日志报错"><a href="#Spark-History服务器角色日志报错" class="headerlink" title="Spark-History服务器角色日志报错"></a>Spark-History服务器角色日志报错</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>hue所在服务器，hue日志报错，报错信息如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ERROR org.apache.spark.deploy.history.FsHistoryProvider: Exception encountered when attempting to load application log hdfs:&#x2F;&#x2F;namenode:8020&#x2F;user&#x2F;spark&#x2F;applicationHistory&#x2F;application_1535095516394_0427_1</span><br><span class="line">java.io.IOException: Cannot obtain block length for LocatedBlock&#123;BP-1887898532-ip-1512095816745:blk_1101057640_27555806; getBlockSize()&#x3D;807773; corrupt&#x3D;false; offset&#x3D;0; locs&#x3D;[DatanodeInfoWithStorage[ip:50010,DS-6ebdd2c0-dbd5-43df-ab07-6029dadd02bc,DISK]]&#125;</span><br><span class="line">        at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:431)</span><br><span class="line">        at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:337)</span><br><span class="line">        at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:273)</span><br><span class="line">        at org.apache.hadoop.hdfs.DFSInputStream.&lt;init&gt;(DFSInputStream.java:265)</span><br><span class="line">        at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1588)</span><br><span class="line">        at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:335)</span><br><span class="line">        at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:331)</span><br><span class="line">        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)</span><br><span class="line">        at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:331)</span><br><span class="line">        at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:784)</span><br><span class="line">        at org.apache.spark.scheduler.EventLoggingListener$.openEventLog(EventLoggingListener.scala:350)</span><br><span class="line">        at org.apache.spark.deploy.history.FsHistoryProvider.org$apache$spark$deploy$history$FsHistoryProvider$$replay(FsHistoryProvider.scala:577)</span><br><span class="line">        at org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$16.apply(FsHistoryProvider.scala:410)</span><br><span class="line">        at org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$16.apply(FsHistoryProvider.scala:407)</span><br><span class="line">        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:251)</span><br><span class="line">        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:251)</span><br><span class="line">        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)</span><br><span class="line">        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)</span><br><span class="line">        at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:251)</span><br><span class="line">        at scala.collection.AbstractTraversable.flatMap(Traversable.scala:105)</span><br><span class="line">        at org.apache.spark.deploy.history.FsHistoryProvider.org$apache$spark$deploy$history$FsHistoryProvider$$mergeApplicationListing(FsHistoryProvider.scala:407)</span><br><span class="line">        at org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$checkForLogs$3$$anon$4.run(FsHistoryProvider.scala:309)</span><br><span class="line">        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</span><br><span class="line">        at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure>

<h2 id="排查"><a href="#排查" class="headerlink" title="排查"></a>排查</h2><p>日志显示历史文件读写无法进行</p>
<ol>
<li>通过<code>hdfs dfs -get /user/spark/applicationHistory/application_1535095516394_0427_1</code>提示当前用户没有权限</li>
<li><code>hdfs dfs -ls /user/spark/applicationHistory/application_1535095516394_0427_1</code>，创建用户/用户组为`**/spark</li>
<li>切换为<code>spark</code>用户组用户，命令<code>cat /etc/passwd</code>发现该用户组被禁用,修改<code>/etc/passwd</code>中<code>spark</code>用户的<code>/sbin/nologin</code>-&gt;<code>/bin/bash</code></li>
<li>使用<code>su spark</code>登录该用户，删除<code>/user/spark/applicationHistory/application_1535095516394_0427_1</code>文件到回收站</li>
<li>重新查看日志，不再报错</li>
</ol>
]]></content>
      <categories>
        <category>问题排查</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>redis 集群搭建以及监测环境</title>
    <url>/2018/08/08/redis%20%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%8F%8A%E7%9B%91%E6%B5%8B%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h1 id="redis-集群搭建以及监测环境"><a href="#redis-集群搭建以及监测环境" class="headerlink" title="redis 集群搭建以及监测环境"></a>redis 集群搭建以及监测环境</h1><p>按照官网的指导，要实现3主3从的集群 虚拟机单机ip:192.168.40.128</p>
<h2 id="集群基本搭建"><a href="#集群基本搭建" class="headerlink" title="集群基本搭建"></a>集群基本搭建</h2><h3 id="简单下载"><a href="#简单下载" class="headerlink" title="简单下载"></a>简单下载</h3><ul>
<li>通过 <code>wget http://download.redis.io/releases/redis-4.0.10.tar.gz</code></li>
<li>解压缩 <code>tar zxvf redis-4.0.10.tar.gz</code></li>
<li>指定安装路径，切换root用户执行<code>make &amp;&amp; make PREFIX=/usr/local/redis install</code>，可能出现权限不够的问题，sudo同样会报错，直接使用root进行操作。</li>
</ul>
<h3 id="安装编译工具"><a href="#安装编译工具" class="headerlink" title="安装编译工具"></a>安装编译工具</h3><ul>
<li><code>sudo apt-get update</code></li>
<li><code>sudo apt-get install gcc</code></li>
<li><code>sudo apt-get install make</code></li>
<li><code>sudo apt-get install tcl</code></li>
</ul>
<h3 id="创建redis集群文件夹"><a href="#创建redis集群文件夹" class="headerlink" title="创建redis集群文件夹"></a>创建redis集群文件夹</h3><ul>
<li>因为是/usr，所以始终都是在root权限下进行操作</li>
<li><code>cd /usr/local/redis</code></li>
<li><code>mkdir cluster</code></li>
<li><code>cd cluster</code></li>
<li><code>mkdir 7000 7001 7002 7003 7004 7005</code></li>
</ul>
<h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p>复制redis conf内的config文件复制到六个文件夹中，并且修改以下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 端口号  </span><br><span class="line">port 7000  </span><br><span class="line"># 后台启动  </span><br><span class="line">daemonize yes  </span><br><span class="line"># 开启集群  </span><br><span class="line">cluster-enabled yes  </span><br><span class="line">#集群节点配置文件  </span><br><span class="line">cluster-config-file nodes-7000.conf  </span><br><span class="line"># 集群连接超时时间  </span><br><span class="line">cluster-node-timeout 5000  </span><br><span class="line"># 进程pid的文件位置  </span><br><span class="line">pidfile &#x2F;home&#x2F;ubuntu&#x2F;redis-4.0.10&#x2F;pid&#x2F;redis-7000.pid</span><br><span class="line">#工作文件夹</span><br><span class="line">dir &quot;&#x2F;home&#x2F;ubuntu&#x2F;redis-4.0.10&#x2F;working&quot;</span><br><span class="line"># 开启aof  </span><br><span class="line">appendonly yes  </span><br><span class="line"># aof文件路径  </span><br><span class="line">appendfilename &quot;appendonly-7005.aof&quot;  </span><br><span class="line"># rdb文件路径  </span><br><span class="line">dbfilename dump-7000.rdb</span><br></pre></td></tr></table></figure>

<p>redis的配置文件中的bind指定的是redis服务器的网卡ip，也就是redis服务器的ip</p>
<h3 id="启动脚本"><a href="#启动脚本" class="headerlink" title="启动脚本"></a>启动脚本</h3><ul>
<li><code>cd /home/ubuntu/redis-4.0.10/</code></li>
<li><code>touch start.link.sh</code>为了操作简单,创建脚本</li>
<li>修改启动脚本，为</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">export BASE_FLOD="/usr/local/redis"</span><br><span class="line">&#123;BASE_FLOD&#125;/bin/redis-server /usr/local/redis/cluster/7000/redis.conf</span><br><span class="line">/usr/local/redis/bin/redis-server /usr/local/redis/cluster/7001/redis.conf</span><br><span class="line">/usr/local/redis/bin/redis-server /usr/local/redis/cluster/7002/redis.conf</span><br><span class="line">/usr/local/redis/bin/redis-server /usr/local/redis/cluster/7003/redis.conf</span><br><span class="line">/usr/local/redis/bin/redis-server /usr/local/redis/cluster/7004/redis.conf</span><br><span class="line">/usr/local/redis/bin/redis-server /usr/local/redis/cluster/7005/redis.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">cd</span> src</span></span><br><span class="line"><span class="meta">#</span><span class="bash">./redis-trib.rb create --replicas 1 192.168.40.128:7000 192.168.40.128:7001 192.168.40.128:7002 192.168.40.128:7003 192.168.40.128:7004 192.168.40.128:7005</span></span><br></pre></td></tr></table></figure>

<p>其中注释的是为了简化初始启动的，ip需要跟每个节点配置的redis.conf中bind属性绑定的一致</p>
<ul>
<li>启动后可以通过ps -ef | grep redis命令查询对应的线程是否启动</li>
</ul>
<h3 id="集群启动"><a href="#集群启动" class="headerlink" title="集群启动"></a>集群启动</h3><ul>
<li>关联程序使用的ruby写的，所以要搭建rudy的运行环境，需要安装rudbygem</li>
<li><code>sudo apt-get install ruby rubygems -y</code></li>
<li>gem install redis,运行到这里会感觉十分慢，需要耐心等待，在redis安装目录下，src文件夹redis-trib.rb</li>
<li>运行<code>redis-trib.rb create --replicas 1 192.168.40.128:7000 192.168.40.128:7001 192.168.40.128:7002 192.168.40.128:7003 192.168.40.128:7004 192.168.40.128:7005</code>,检查配置的信息是否有错误，没有直接yes就可以.  <code>[OK] All 16384 slots covered.</code>代表接群启动成功。</li>
</ul>
<h3 id="节点查看，重启"><a href="#节点查看，重启" class="headerlink" title="节点查看，重启"></a>节点查看，重启</h3><p>查看集群运行状态：使用命令<code>./redis-trib.rb check 192.168.40.128:7000</code>，进行集群的状态检查</p>
<h3 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h3><h4 id="自带测试工具redis-benchmark"><a href="#自带测试工具redis-benchmark" class="headerlink" title="自带测试工具redis-benchmark"></a>自带测试工具redis-benchmark</h4><ul>
<li><code>redis-benchmark -h 192.168.40.128 -p 6379 -c 100 -n 100000</code>100个并发连接，100000个请求，检测 host为localhost 端口为6379的 redis 服务器性能。</li>
<li><code>redis-benchmark -h 192.168.40.128 -p 6379 -q -d 100</code><br>测试存取大小为100字节的数据包的性能。</li>
<li><code>redis-benchmark -t set,lpush -n 100000 -q</code><br>只测试某些操作的性能。</li>
<li><code>redis-benchmark -n 100000 -q script load &quot;redis.call(‘set’,’foo’,’bar’)&quot;</code>只测试某些数值存取的性能。</li>
</ul>
<h3 id="集群密码设置"><a href="#集群密码设置" class="headerlink" title="集群密码设置"></a>集群密码设置</h3><p>集群搭建初始不需要密码，启动完成后，先看每个节点的配置文件是否有读写权限，如果没有读写权限，需要chmod修改的读写权限，通过</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./redis-cli -c -p port</span><br><span class="line">config set masterauth password</span><br><span class="line">config set requirepass password</span><br><span class="line">config rewrite</span><br></pre></td></tr></table></figure>

<p>分别连接每个节点进行设置。<br>若要重启发现连接不上，修改启动脚本 redis-.sh 99行，配置启动脚本密码启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">@r = Redis.new(:host =&gt; @info[:host], :port =&gt; @info[:port], :timeout =&gt; 60,:password =&gt; "yangfan@1995")</span><br></pre></td></tr></table></figure>

<h3 id="代码测试"><a href="#代码测试" class="headerlink" title="代码测试"></a>代码测试</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *集群连接测试</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testJedisCluster</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Set&lt;HostAndPort&gt; nodes = <span class="keyword">new</span> LinkedHashSet&lt;&gt;();</span><br><span class="line">    <span class="comment">//所有主机节点ip和端口</span></span><br><span class="line">    nodes.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.40.128"</span>, <span class="number">7000</span>));</span><br><span class="line">    nodes.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.40.128"</span>, <span class="number">7001</span>));</span><br><span class="line">    nodes.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.40.128"</span>, <span class="number">7002</span>));</span><br><span class="line">    nodes.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.40.128"</span>, <span class="number">7003</span>));</span><br><span class="line">    nodes.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.40.128"</span>, <span class="number">7004</span>));</span><br><span class="line">    nodes.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.40.128"</span>, <span class="number">7005</span>));</span><br><span class="line">    <span class="comment">//没有密码</span></span><br><span class="line">    <span class="comment">//JedisCluster cluster = new JedisCluster(nodes);</span></span><br><span class="line">    <span class="comment">//添加密码调用</span></span><br><span class="line">    JedisCluster cluster = <span class="keyword">new</span> JedisCluster(nodes, <span class="number">5000</span>, <span class="number">5000</span>, <span class="number">10</span>, <span class="string">"yangfan@1995"</span>, <span class="keyword">new</span> GenericObjectPoolConfig());</span><br><span class="line">    <span class="comment">//cluster.zadd("test_1", String.valueOf(""),"id_2");</span></span><br><span class="line">    System.out.println(cluster.zscore(<span class="string">"test_1"</span>, <span class="string">"id_1"</span>));</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        cluster.close();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="主从模式、哨兵、集群的关系"><a href="#主从模式、哨兵、集群的关系" class="headerlink" title="主从模式、哨兵、集群的关系"></a>主从模式、哨兵、集群的关系</h3><ol>
<li>主从模式是指定复制和持久化关系，指定了主从备份的关系</li>
<li>哨兵：当主数据库遇到异常中断服务后，开发者可以通过手动的方式选择一个从数据库来升格为主数据库，以使得系统能够继续提供服务。主要是为了解决主从复制手动切换主从关系的检测工具，可以自动切换主从。</li>
<li>使用哨兵，redis每个实例也是全量存储，每个redis存储的内容都是完整的数据，浪费内存且有木桶效应。为了最大化利用内存，可以采用集群，就是分布式存储。即每台redis存储不同的内容，共有16384个slot。每个redis分得一些slot，hash_slot = crc16(key) mod 16384 找到对应slot，键是可用键，如果有{}则取{}内的作为可用键，否则整个键是可用键集群至少需要3主3从，且每个实例使用不同的配置文件，主从不用配置，集群会自己选。</li>
</ol>
<h2 id="监控部署"><a href="#监控部署" class="headerlink" title="监控部署"></a>监控部署</h2><h3 id="RedisLive搭建部署"><a href="#RedisLive搭建部署" class="headerlink" title="RedisLive搭建部署"></a>RedisLive搭建部署</h3><h4 id="运行环境部署"><a href="#运行环境部署" class="headerlink" title="运行环境部署"></a>运行环境部署</h4><ol>
<li><p><code>git clone https://github.com/kumarnitin/RedisLive.git</code> 下载redislive,解压缩<code>unzip -o -d /home/ubuntu/ RedisLive-master.zip</code></p>
</li>
<li><p>进入文件夹 <code>pip install -r requirements.txt -i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com</code><br>指定豆瓣源，下载速度更快。</p>
</li>
<li><p>进入src文件夹，复制example文件，编辑</p>
</li>
</ol>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"RedisServers"</span>:</span><br><span class="line">    [</span><br><span class="line">        &#123;</span><br><span class="line">        <span class="attr">"server"</span>: <span class="string">"192.168.40.128"</span>,</span><br><span class="line">        <span class="attr">"port"</span> : <span class="number">7000</span>,</span><br><span class="line">        <span class="attr">"password"</span> : <span class="string">"yangfan@1995"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment">//...多个监听</span></span><br><span class="line">    ],</span><br><span class="line"></span><br><span class="line">    <span class="attr">"DataStoreType"</span> : <span class="string">"redis"</span>,</span><br><span class="line"></span><br><span class="line">    <span class="attr">"RedisStatsServer"</span>: <span class="comment">//存储的redis监听接口</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"server"</span> : <span class="string">"127.0.0.1"</span>,</span><br><span class="line">        <span class="attr">"port"</span> : <span class="number">6379</span></span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    <span class="attr">"SqliteStatsStore"</span> :</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"path"</span>:  <span class="string">"/home/ubuntu/redis-4.0.10/working/redislive.db"</span> <span class="comment">//进行存储的文件</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li><p><code>ubuntu@ubuntu:~/redis-4.0.10$ mkdir pid</code><br><code>ubuntu@ubuntu:~/redis-4.0.10$ mkdir log</code><br><code>ubuntu@ubuntu:~/redis-4.0.10$ mkdir working</code> //保存aof，rdb，node-config文件</p>
</li>
<li><p>RedisLive分为两部分，其中一部分为监控脚本，另一部分为web服务，所以需要分别启动。<br><code>./redis-monitor.py --duration=120</code><br><code>./redis-live.py</code></p>
</li>
<li><p>访问<a href="http://192.168.40.128:8888/index.html" target="_blank" rel="noopener">http://192.168.40.128:8888/index.html</a></p>
</li>
</ol>
<h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><ol>
<li>redis.clients.jedis.exceptions.JedisNoReachableClusterNodeException: No reachable node in cluster<br>redis node的redis.conf 绑定ip设置为指定的redis节点ip，启动集群时只用指定ip启动，不使用192.168.40.128</li>
<li>connect refuse<br>关闭防火墙</li>
<li>No module named redis<ul>
<li>查看python位置 <code>which python</code></li>
<li>先备份 <code>sudo cp /usr/bin/python /usr/bin/python_cp</code></li>
<li>删除 <code>sudo rm /usr/bin/python</code></li>
<li>默认设置成python3.5，创建链接 <code>sudo ln -s /usr/bin/python3.5 /usr/bin/python</code></li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>开发部署</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title>开源协议简介以及使用</title>
    <url>/2017/06/24/%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE%E7%AE%80%E4%BB%8B%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h1 id="开源协议简介以及使用"><a href="#开源协议简介以及使用" class="headerlink" title="开源协议简介以及使用"></a>开源协议简介以及使用</h1><h2 id="开源协议简介"><a href="#开源协议简介" class="headerlink" title="开源协议简介"></a>开源协议简介</h2><h3 id="什么是开源协议"><a href="#什么是开源协议" class="headerlink" title="什么是开源协议"></a>什么是开源协议</h3><p>开源协议是针对电脑软件或者其他产品规定，允许在指定的条件下或限制下，使用修改源代码、分享蓝图或设计的公共协议，不同的协议中定义了个人或者公司是否使用开源代码进行修改、设计使用、商用以及是否需要标注来源。</p>
<h3 id="为什么需要开源协议"><a href="#为什么需要开源协议" class="headerlink" title="为什么需要开源协议"></a>为什么需要开源协议</h3><p>开源协议是证明软件版权的有力证据，这里就要提到软著(计算机软件著作权)，软件著作权是国内对于软件版权的保护证明，但是软著对于版本更新支持不好，每次更新迭代都是要重新注册。</p>
<p>开源协议上虽然在国内没有明确的法律支撑，但是却是软件版权的有利证明，并且对于更新迭代支持更好。</p>
<h2 id="开源协议列表"><a href="#开源协议列表" class="headerlink" title="开源协议列表"></a>开源协议列表</h2><h3 id="常用开源协议"><a href="#常用开源协议" class="headerlink" title="常用开源协议"></a>常用开源协议</h3><h4 id="Apache-License-2-0"><a href="#Apache-License-2-0" class="headerlink" title="Apache License 2.0"></a>Apache License 2.0</h4><p>Apache 背书的常用协议，Apache很多开源项目都用到了，以下是协议内容：</p>
<ol>
<li>永久免费的全球性的不可撤销的版本许可</li>
<li>允许复制、公开以及其衍生内容</li>
<li>允许对内容商用化</li>
<li>修改内容必须显著声明，且保留原始源作品中的版权、商标等信息</li>
<li>在与Apache协议不冲突情况下允许在衍生内容中添加自己的许可</li>
</ol>
<h4 id="BSD"><a href="#BSD" class="headerlink" title="BSD"></a>BSD</h4><p>The BSD License（BSD）是Berkeley Software Distribution License（柏克莱软体散布授权条款）的缩写，许多软体是在此一授权条款下发布的。</p>
<p>以下是 BSD 2-Clause协议内容：</p>
<ol>
<li>源代码的再分发必须保留上述版权声明、本条件列表和以下免责声明</li>
<li>源代码修改后必须在内容中标识版权声明</li>
</ol>
<p>BSD 3-Clause 协议在 BSD 2-Clause基础上添加了</p>
<ol>
<li>未经事先书面许可，不得使用版权所有者或其贡献者的名称来认可或推广本软件衍生的产品</li>
</ol>
<h4 id="GNU-General-Public-License-GPL"><a href="#GNU-General-Public-License-GPL" class="headerlink" title="GNU General Public License (GPL)"></a>GNU General Public License (GPL)</h4><p>由 MIT 教授理查德·斯托曼（Richard Stallman）提出应将软件源码看成人类共同拥有的知识财富，应该公开地自由交换、修改提出了GNU计划并建立了自由软件基金会;同时，发布了一份举足轻重的法律文件，GNU 通用公共授权书(GPL)，主要分为版本2和版本3，主要区别是版本3中添加免责声明等附加内容。</p>
<p>以下是GPL协议内容：</p>
<ol>
<li>允许对代码复制、编辑</li>
<li>允许衍生内容商用</li>
<li>衍生的产品必须开源,并且不得限制公开权益，不允许修改后和衍生的代码做为闭源的商业软件发布和销售</li>
<li>必须声明来源并且需要声明原有的协议</li>
</ol>
<h4 id="GNU-Library-or-“Lesser”-General-Public-License-LGPL"><a href="#GNU-Library-or-“Lesser”-General-Public-License-LGPL" class="headerlink" title="GNU Library or “Lesser” General Public License (LGPL)"></a>GNU Library or “Lesser” General Public License (LGPL)</h4><p>根据GPL协议的规定，所有的衍生内容必须开源，就会导致一个现象，有部分开源项目库如果是GPL协议并且没有替代的方案，这时如果一个非开源项目想要使用这部分项目内容就必须开源，就会与开发者的想法矛盾，因此LGPL诞生了。</p>
<p>允许以动态链接使用开源库，同时，调用了该库的函数的那部分代码还是要开源的，除此之外的部分不需要开源。</p>
<h4 id="MIT-license"><a href="#MIT-license" class="headerlink" title="MIT license"></a>MIT license</h4><p>MIT许可协议之名源自麻省理工学院（Massachusetts Institute of Technology, MIT），又称“X许可协议”（X License）或“X11许可协议”（X11 License）</p>
<ol>
<li>允许对源码进行修改、发布、公开</li>
<li>必须包含著作权声明和许可声明</li>
</ol>
<h4 id="Mozilla-Public-License-2-0"><a href="#Mozilla-Public-License-2-0" class="headerlink" title="Mozilla Public License 2.0"></a>Mozilla Public License 2.0</h4><p>MPL是The Mozilla Public License的简写，是1998年初Netscape的 Mozilla小组为其开源软件项目设计的软件许可证。</p>
<p>MPL协议与LGPL协议类似，如在已有的源代码库上加一个接口，除了接口程序的源代码以MPL许可证的形式对外许可外，源代码库中的源代码就可以不用MPL许可证的方式强制对外许可。</p>
<h4 id="Common-Development-and-Distribution-License-CDDL"><a href="#Common-Development-and-Distribution-License-CDDL" class="headerlink" title="Common Development and Distribution License(CDDL)"></a>Common Development and Distribution License(CDDL)</h4><p>CDDL（Common Development and Distribution License，通用开发与发行许可）开源协议，是MPL（Mozilla Public License）的扩展协议，它允许公共版权使用，无专利费，并提供专利保护，可集成于商业软件中，允许自行发布许可，修改后的代码版权归软件的发起者。</p>
<h4 id="Eclipse-Public-License-version-2-0"><a href="#Eclipse-Public-License-version-2-0" class="headerlink" title="Eclipse Public License version 2.0"></a>Eclipse Public License version 2.0</h4><p>Eclipse Public License（EPL）是一个与CPL相类似的许可证，任何扩展自Eclipse源码的代码也必须是开源的。</p>
<ol>
<li>EPL允许Recipients任意使用、复制、分发、传播、展示、修改以及改后闭源的二次商业发布。</li>
<li>将源码的整体或部分再次开源发布的时候,必须继续遵循EPL开源协议来发布,而不能改用其他协议发布</li>
<li>要发布修改后的源码时必须声明源代码可获取且要告知获取方法</li>
<li>需要将EPL下的源码作为一部分跟其他私有的源码混合发布时，EPL代码需要使用EPL协议，其余模块可以不用开源</li>
</ol>
<h2 id="开源协议使用"><a href="#开源协议使用" class="headerlink" title="开源协议使用"></a>开源协议使用</h2><h3 id="github-gitlab-添加"><a href="#github-gitlab-添加" class="headerlink" title="github/gitlab 添加"></a>github/gitlab 添加</h3><p>在仓库中直接添加比较简单，通过<code>Add file</code>文件<br><img src="https://i.loli.net/2021/08/26/sduzKnjhiQrVCvX.png" alt="截屏2021-08-26 01.04.52"><br>将文件名称命名为LICENSE，会自动提示右侧的<code>Choose a license template</code></p>
<p><img src="https://i.loli.net/2021/08/26/PiLlkt9xIQeJg5N.png" alt="截屏2021-08-26 01.03.19"><br>选择好对应的开源协议，添加到自己的项目中。<br><img src="https://i.loli.net/2021/08/26/iQDUXbkPx1wfoKl.png" alt="截屏2021-08-26 01.03.34"></p>
<h3 id="idea-添加"><a href="#idea-添加" class="headerlink" title="idea 添加"></a>idea 添加</h3><p>idea是可以直接通过新建文件的方式，来选择建立不同需求上的开源协议的。</p>
<blockquote>
<p>New-&gt;License file-&gt; 选择需要使用的开源协议<br>操作如下图：</p>
</blockquote>
<p><img src="https://i.loli.net/2021/08/26/LQHMNeXEZc9DSmf.png" alt="截屏2021-08-26 00.56.52"></p>
<h3 id="直接创建"><a href="#直接创建" class="headerlink" title="直接创建"></a>直接创建</h3><p>当没有编译器或者没有具体的网页操作时，可以简单的通过记事本方式，将需要使用的开源协议的规范内容COPY到文件中，命名为<code>LICENSE</code></p>
<h2 id="参考内容"><a href="#参考内容" class="headerlink" title="参考内容"></a>参考内容</h2><ol>
<li><a href="https://opensource.org/licenses" target="_blank" rel="noopener">Open Source Initiative</a></li>
<li><a href="http://www.ruanyifeng.com/blog/2010/02/why_gpl_is_a_better_choice.html" target="_blank" rel="noopener">为什么GPL是更好的开源许可证?</a></li>
<li><a href="https://en.wikipedia.org/wiki/Open-source_license" target="_blank" rel="noopener">开源协议说明</a></li>
<li><a href="https://zh.wikipedia.org/wiki/GNU通用公共许可证" target="_blank" rel="noopener">GNU通用公共许可证</a></li>
<li><a href="http://c.biancheng.net/view/674.html" target="_blank" rel="noopener">GPL协议和自由软件</a></li>
</ol>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>开发部署</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop技术内幕-源代码环境准备</title>
    <url>/2016/03/29/%E6%BA%90%E4%BB%A3%E7%A0%81%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/</url>
    <content><![CDATA[<h1 id="源代码环境准备"><a href="#源代码环境准备" class="headerlink" title="源代码环境准备"></a>源代码环境准备</h1><h3 id="Hadoop生态环境"><a href="#Hadoop生态环境" class="headerlink" title="Hadoop生态环境"></a>Hadoop生态环境</h3><ul>
<li>Hadoop Common:配置、远程RPC、序列化机制、抽象文件系统</li>
<li>Avro:数据序列化系统</li>
<li>Zookeeper:统一命名服务、状态同步、集群管理、分布式应用配置</li>
<li>HDFS:分布式文件系统</li>
<li>MR:计算模型，对分布式并行环境处理数据</li>
<li>HBase:增强的稀疏排序，可以和MR完美结合</li>
<li>Hive:数据仓库架构，数据ETL工具，数据存储管理</li>
<li>Pig:针对大型数据集进行分析和评估的平台</li>
<li>Mahout:数据挖掘处理架构</li>
<li>X-RIME:社会网络分析工具</li>
<li>Crossbow:基因测序等海量计算</li>
<li>Chukwa:监控大规模分布式系统的数据收集开源系统</li>
<li>Flume:日志收集系统</li>
<li>Sqoop:结构化数据和Hadoop之间进行数据交换</li>
<li>Oozie:数据工作流处理</li>
</ul>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
</search>
